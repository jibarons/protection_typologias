# Metodología

## Objeto
El objeto del estudio fue el riesgo de protección entendido desde la óptica de la acción humanitaria en Cisjordania, territorios ocupados Palestinos. Para ello, propusimos la construcción de una tipología de riesgos de protección. Como resultado del análisis para la tipología, se creó un índice de riesgo de protección, un valor sintético que consolidaba todos los factores del riesgo de protección. Para complementar a la tipología y dar valor explicativo al objeto de estudio, se desarrolló una profundización cualitativa, planteando una vinculación sistémica entre datos cualitativos y cuantitativos.

## Fuentes de Datos
El estudio se realizó con dos tipos de datos secundarios: cuantitativos, recogidos siguiendo el método de encuesta con entrevista estructuradas; cualitativos, recogidos por medio de grupos de discusión con entrevista abierta.

Los datos cuantitativos se obtuvieron de la Evaluación de Necesidades Multi-Sectorial realizada por @reach_multi-sectorial_2022 en junio de 2022. La encuesta entrevistó a un total de `r fmat_num(nrow(hh_data))` hogares. Este tipo de encuestas son comunes en el sector humanitario, en contextos de crisis, para la identificación de necesidades de la población. En particular, esta encuesta plantea como unidad muestral primaria las comunidades de los territorios palestinos, y como una muestral básica el hogar. Siguió un diseño muestral probabilístico, estratificado por conglomerados en dos fases. La encuesta abarcó todos los territorios palestinos: Gaza y Cisjordania. 

Aquí trabajamos sólo con los `r fmat_num(nrow(indicators_data))` hogares para Cisjordania. La encuesta cubrió todos los Governorados de Cisjordania, separando en estratos independientes las áreas Oslo A y B, el área de Oslo C y los campos de refugiados para cada Governorado, además de la zona especial de Hebrón H2 y la zona especial de Jerusalén Este. Los datos fueron estadísticamente representativos con un nivel de confianza del $95%$ y un margen de error del $\pm9%$ para todos los estratos. Excepto para el de campos de refugiados en Cisjordania con un error del $\pm5%$. Con los datos provenientes de esta encuesta se desarrolló el sistema de indicadores para la medición del riesgo de protección y la identificación de tipologías de riesgo de protección. 

Los datos cualitativos fueron recogidos por medio del ECP implementado por We World. Estos datos se recogieron en las comunidades sobre las que interviene el Consocio de Protección Comunitario, del cual We World era miembro. La unidad de análisis para estos datos era la comunidad. Para cada una de las `r fmat_num(nrow(cluster))` comunidades se realizó un muestreo socio-estructural (Montañés, 2012; Prieto & March, 2002) para identificar los grupos de población más relevantes a incluir en los grupos de discusión, a la vez que identificar barreras comunicativas y determinar el número de grupos de discusión por comunidad. Como base de la segmentación. Cada comunidad quedó estructurada según criterios de edad y género, siendo el género un factor crítico para la separación entre grupos. En cada comunidad se realizaron al menos dos grupos de discusión, uno para hombres y otro para mujeres, incluyendo perfiles de diferente edad. 

La información recogida en cada uno de los grupos de discusión no se pudo grabar, debido a cuestiones de confidencialidad y sensibilidad de los temas tratados. La información cualitativa registrada salió de las notas de los cuadernos de campos de los entrevistadores. Para asegurar que la mayor parte de la información quedara registrada correctamente y con el mayor nivel de detalle, dos personas del equipo de campo participaron en cada grupo: uno como tomador de notas, otra como facilitador del grupo. Las notas de campo fueron pasadas a un software diseñado específicamente por We World para clasificar la información de los grupos de discusión. Este software permite la entrada de párrafos completos de información para su posterior fragmentación en unidades de análisis. Cada una de estas unidades de análisis dispone de una lista predefinida de categorías para clasificar la información, si bien se puede seleccionar la opción "Otro" para añadir nuevas categorías. Este proceso está inspirado en programas de codificación de información cualitativa como es Atlas.ti, si bien su funcionalidad y mucho más básica y dirigida a este propósito. Los datos cualitativos se usaron para triangular con la información cuantitativa y dar contenido explicativo a la tipología de riesgo de protección.  

## Diseño de Análisis
El diseño de análisis se estructura en tres fases de análisis: 1) Índice de riesgo de protección; 2) Tipología estructura de los riesgos de protección; y 3) Profundización cualitativa.

###	Índice de riesgo de protección
Para desarrollar el índice de protección, primero tuvimos que identificar un conjunto de indicadores que representan factores de riesgo de protección. Cada uno de estos indicadores sintetiza una serie de preguntas del cuestionario por medio de operaciones lógicas o matemáticas. La construcción de este conjunto de indicadores se basaba en su metodología en los conceptos descritos por @lazarsfeld_evidence_1958 y @lopez-roldan_medicion_2015 y, técnicamente en los estándares sentados por @nardo_tools_2005 y @oecd_handbook_2008. En esta línea, la construcción del índice de riesgo de protección implica un proceso de medición de una problemática abstracta y descrita teóricamente, hacia a un sistema de indicadores observables y medibles empíricamente hasta alcanzar un estado de isomorfismo en el que lo observable constituye una representación empírica fiable de lo teórico [@lopez-roldan_medicion_2015]. Los criterios para la selección de los indicadores se inspiraron en los definidos por @united_nations_statistics_division_discussion_2015 para definir los Indicadores de Desarrollo Sostenible. En concreto fueron los siguientes:

* Guiados por la teoría: los indicadores se basan en los marcos teóricos presentados y se pueden categorizar en los dos marcos al mismo tiempo, riesgo de protección como amenaza, vulnerabilidad o capacidad, o en el marco de la seguridad y la dignidad.
* Aplicable al nivel apropiado: Para el monitoreo global, los indicadores deben ser relevantes para todos los países. Para el monitoreo nacional, los indicadores deben ser relevantes para las prioridades nacionales. En nuestro caso, nos centramos en el nivel local
* Coherente y complementario: Los indicadores deben ser coherentes y complementarios entre sí en el marco de seguimiento, asegurando la interdependencia de los indicadores, pero evitando la redundancia. Especialmente, para un análisis de reducción de la dimensionalidad como el que planteamos.
* Probado para ser valioso: a través del análisis empírico, los indicadores deben garantizar la variabilidad y la capacidad para caracterizar un fenómeno específico. Un indicador que es constante en todas las unidades no aporta información relevante, no tiene variación).
* Basados en evidencia: los indicadores deben ser científicamente sólidos y basarse, en la mayor medida posible, en definiciones, clasificaciones, estándares, recomendaciones y mejores prácticas existentes acordadas internacionalmente que justifiquen su creación y respalden su interpretabilidad. Si bien este punto es considerado de vital importancia, se vio limitado por la escasa literatura académica sobre el tema de protección en acción humanitaria.
* Fácil de interpretar y comunicar: los indicadores deben ser claros y fáciles de entender para los responsables de la formulación de políticas, el público en general y otras partes interesadas, y ser inequívocos en su interpretación. Siempre que sea ambiguo, la ambigüedad debe exponerse y aclararse).

Todos estos criterios aseguran la guía necesaria para lograr un sistema parsimonioso donde el número de indicadores sea lo más limitado posible aplicando el principio de la navaja de Ockham “recortando la complejidad innecesaria, dejando solo teorías, modelos e hipótesis lo más simples posibles sin ser falsas”, lo que asegura un sistema de indicadores manejable, relevante e interpretable.

Para asegurar una base de datos lo más completa posible, los indicadores creados serian sometidos al análisis de valores perdidos. Siguiendo las referencias de @cruz_cantero_no_1990 y @oecd_handbook_2008, buscaríamos el balance entre perder información, la complejidad del método de imputación y el número de valores perdidos. La clasificación de los indicadores nos basamos en los marcos teóricos descritos, donde las teorías presentadas relacionadas al riego de protección y a la seguridad y dignidad se complementan para formar una taxonomía para la clasificación de indicadores. Para la agregación del índice de riesgo de protección nos basamos en los trabajos de @asselin_composite_2009 y @ambapour_using_2020 para la medición de la pobreza multidimensional. Partiendo de estas bases, convertimos el conjunto de indicadores en una matriz de indicadores _dummy_ donde $0$ es la ausencia del atributo -factor de riesgo- y $1$ es la presencia del factor de riesgo. 

El Análisis de Correspondencias Múltiples (ACM) se aplicó con la librería de R _FactoMineR_, y se estructuró en tres fases: 1) en la primera se realizó la interpretación de las dos primeras dimensiones, resultantes del ACM; 2) la segunda prosiguió con la selección de los indicadores más relevantes; 3) finalmente, se procedió a el cálculo del indicador compuesto.

Los datos recogidos por @reach_multi-sectorial_2022 con la evaluación de necesidades, la mayoría de las preguntas eran categóricas derivando indicadores en su mayoría categóricos u ordinales. Sobre este tipo de indicadores, con distribuciones discretas, la aplicación del criterio de entropía para la reducción de la dimensionalidad no resulta relevante. El criterio de entropía se aplica principalmente aplicado sobre variables numéricas comprendidas entre $0$ y $1$ [@asselin_composite_2009]. Nos acercamos entonces al concepto de inercia, que en vez de basarse en distancias entre distribuciones –como la entropía– se basa en distancias dentro de la propia distribución, resultando más relevantes para variables categóricas [@asselin_composite_2009]. Bajo el principio de inercia, se proponen distintos análisis destacando entre ellos el análisis de componentes principales y el ACM. El análisis de componentes principales requiere linealidad entre los componentes y las unidades en la misma unidad de medida, criterios que no son factibles para variables categóricas. Mientras que el análisis de componentes principales se focaliza en las distribuciones de las variables -análisis paramétrico- el ACM se focaliza cada una de las categorías -no paramétrico @oecd_handbook_2008. Con ello, el ACM se posiciono como la técnica más apropiada para nuestro objetivo, permitiendo una reducción de la dimensionalidad basada en la inercia sobre una serie de variables eminentemente categóricas [@lopez-roldan_analisis_2015].

Una vez seleccionado el ACM como técnica de análisis, este se aplicó sobre la matriz de indicadores binarios. El ACM incluyo las ponderaciones propias de la encuesta para asegurar que sus resultados eran representativos de la población en Cisjordania. Con ello, se procedió a la interpretación de los resultados. En concreto nos centramos en la interpretación de los dos primeros ejes, esperando que se dibujaran las 3 problemáticas que trazamos en el marco teórico. Estas son: el riesgo de protección y la seguridad y la dignidad. Para la selección de indicadores, en el segundo paso, nos basamos en un criterio propuesto por @asselin_composite_2009: "orden consistente en el primer eje" (FAOC con siglas en ingles). En nuestro caso el criterio FAOC refiere que las categorías del indicador debían ordenarse de forma coherente sobre primer eje -horizontal- de forma que aquellas categorías con mayor coordenada en el primer eje impliquen un mayor riesgo, y viceversa. Solo los indicadores así ordenados se mantuvieron. Para hacer la selección final, también utilizamos el coeficiente $v-test$, que nos permitió evaluar la significación de las contribuciones relativas de la categoría. Entonces, solo mantuvimos aquellos indicadores cuyas 

### Tipologías del riesgo de protección

Para la construcción de las metodologías nos basaremos en el proceso definido por @lopez_roldan_construccion_1996 para la construcción de una tipología estructural y articulada. Este método se compone de tres pasos principales: primero, la identificación de conceptos latentes -realizada en el paso anterior con el ACM; segundo, la clasificación de las unidades de análisis basadas en los nuevos conceptos identificados; tercero, la definición y validación de la tipología emergente. Una primera aproximación de la aplicación del método de tipologías estructurales y articuladas al sector de la protección en acción humanitaria, y en particular al caso de Cisjordania se puede encontrar en @ibarguen_developing_2018.

Con los conceptos latentes -dimensiones- identificados por el ACM, se aplicó un análisis de conglomerados (ACL) para la identificación de tipologías. El analisis se realizo con la librería de R _factoextra_ Comenzamos explorando si las dimensiones emergentes del ACM resultaban susceptibles de análisis de conglomerados. Para evaluar esta característica utilizamos en estadístico de Hopkings propuesto por @lawson_new_1990. El estadístico de Hopkins asume como hipótesis nula que los datos estas distribuidos uniformemente, y por tanto no se identifican conglomerados. En términos generales, cuando el estadístico supera el coeficiente de $0,5$ se rechaza la hipótesis nula y se concluye que la distribución no es uniforme.

Una vez evaluada la susceptibilidad de los datos para el análisis, procedimos a realizar el ACL. Utilizamos el paquete de R “factoextra” para su ejecución. Existen dos familias de ACL principales: ACL jerárquicos y los llamados _k-methods_, y en particular el _k-means_. El modelo jerárquico por el método de Ward "consiste en un proceso progresivo de agregación ascendente de cada uno de los hogares de manera que, en cada etapa, se van añadiendo los hogares que pierden la mínima inercia" [@fachelli_nuevo_2009 pp.91-92]. De esta forma se consiguen conglomerados que agrupan a los hogares más parecidos en el mismo grupo, a la vez que manteniendo la máxima diferencia entre los distintos grupos ideal para la estratificación. Mas aun, @murtagh_wards_2014 refiere la complementariedad entre el método Ward y el ACM, resultando en observaciones equiponderadas en el espacio euclidiano. Sin embargo, el proceso puede resultar en conglomerados solapados, es decir una unidad puede pertenecer a dos grupos a la vez. 

Los ACL de _k-means_, al contrario que los métodos jerárquicos, parten de la definición de unos centroides posicionados aleatoriamente, a partir de la cuales van agrupando por métodos iterativos aquellas unidades más próximas a los centroides. El método _k-means_ es más estricto en la definición de los grupos y no permiten que una unidad pertenezca a dos grupos diferentes, además de ser más eficientes en términos de computación. Sin embargo, requiere la una definición inicial del número de conglomerados, además de generar resultados diferentes, según la posición inicial del centroide, la cual se define aleatoriamente. 

En el punto de medio de las ventajas e inconvenientes de cada método de ACL, surge un método hibrido llamado _k-means_ jerárquico. Este hibrido aplica en un primer momento un ACL jerárquico para identificar el número de grupos y sus centroides respectivos, luego optimiza la clasificación por el método _k-means_, usando los centroides previamente identificados @murtagh_wards_2014. @alcaide_lozano_typological_2019 (p.73), refiere el método de _k-means_ jerárquico en la construcción de la tipología estructural articulada, posicionándolo, con todo, como nuestro método de preferencia.

A pesar de que k-means jerárquico se posiciona como el método preferido, decidimos comparar este con el método jerárquico, siguiendo las recomendaciones de @jiangsheng_shen_using_2007. Para decidir que método mantendríamos, articularíamos la interpretación de los resultados con el análisis de siluetas propuesto por @rousseeuw_silhouettes_1987. De esta forma, el método que ofreciera mejor interpretación teórica, a la vez que mejor consistencia en la agrupación sería el elegido.

Una vez identificados los conglomerados, procede la descripción de los parangones. Los parangones corresponden a la observación media -hogares- de un conglomerado en particular. Cuando los hogares han quedado clasificados en estratos internamente homogéneos, pero externamente heterogéneos, los hogares posicionados en el centroide del conglomerado se posicionan como parangones @alcaide_lozano_typological_2019. De entre los diferentes tipos de parangón señalados por @alcaide_lozano_typological_2019, en nuestro caso lo utilizaremos principalmente como descriptor. Como tal, el parangón mantiene un paralelismo con el concepto Weberiano de tipo ideal. El parangón describe las características ideales del grupo, mientras que el resto de las observaciones en el conglomerado se asemeja a este tipo ideal sin llegar a alcanzarlo.

### Profundización cualitativa

Para la profundización cualitativa nos servimos de los datos de de una organización humanitaria que contenía información cualitativa capturada por medio de grupos de discusión sobre comunidades donde opera un consorcio de organizaciones humanitarias. En un primer momento planteamos encontrar el vínculo entre las bases de datos -cuantitativa y cualitativo- al nivel más reducido posibles. Para llevarlo a cabo propusimos inferir el conglomerado al que correspondía cada comunidad analizada en los grupos de discusión de cualitativos -a.k.a. comunidades cualitativas. En un primer momento nos planteamos servirnos de sistemas de información geográfica, en concreto la técnica del teselado de Voronoi. Así, se asignaron los conglomerados a las comunidades cualitativas según se comprendieran dentro del polígono Voronoi trazado con las comunidades cuantitativas. A todas las comunidades cualitativas comprendidas dentro de un polígono Voronoi se les asignaría el mismo clúster que al de la comunidad cuantitativa sobre la que se ha creado ese polígono. 

Esta técnica pudiera ser factible en otros contextos donde el riesgo de protección estuviera geográficamente distribuido de forma más heterogénea y delimitadas. Sin embargo, en el contexto Palestino la distancia geográfica no es un factor relevante para el riesgo de protección. Cinco kilómetros de distancia pueden marcar la diferencia si nos encontramos en un área Oslo diferente, o al otro lado de un _checkpoint_. Por el contrario, diez kilómetros de distancia en el mismo área Oslo A, he incluso en el área Oslo A de otro Governorado podría tener las mismas características en cuanto a riesgo fe protección. Ante la imposibilidad de juntar dos bases de datos independientes, recogidas a dos niveles diferentes y sin la misma cobertura geográfico, propusimos usar los datos cualitativos para ahondar en el área Oslo C de Cisjordania. Para ello propusimos un análisis de sentimientos y otro de coocurrencias sobre la información obtenida los grupos de discusión mantenidos en estas localidades. Para realizar estos análisis de minería de textos, usamos el programa R y las librerías _tidytext_ y _widyr_. Nos guiamos con el trabajo de @silge_text_2017 para las cuestiones técnicas,

El análisis de sentimiento en la acción humanitaria a cobrado importancia en el ámbito de la emergencia antes desastres, en lo que se ha venido llamando _Disaster Sentiment Analysis_ (@baro_disaster_2020 y @muztahid_sentiment_2021). Sin embargo, no se encuentran aplicaciones del análisis de sentimiento sobre grupos de discusión realizados con beneficiarios de acción humanitaria. Aplicamos un enfoque de lexicón al análisis de sentimiento, este enfoque parte de un grupo de palabras a las que se le asigna una carga positiva o negativa, según la dirección del sentimiento que genera. Dado el caso específico de Palestina, consideramos que lexicón existentes -principalmente desarrollados para textos extraídos de las redes sociales- no generarían resultados relevantes. Así, filtramos todas las palabras con una frecuencia correspondiente al tercer cuartil o más, es decir, el $25%$ de palabras con más apariciones. De esta lista, filtramos todas aquellas que no contuvieran carga valor semántico -_stop words_. Estas son en su mayoría pronombres, artículos, conjunciones y algunas preposiciones. Para ello usamos todas las listas de _stop words_ disponibles en la librería _tidytext_. Con las palabras restantes, creamos nuestro propio lexicon asignando la carga emocional no a la palabra en sí, si no a su raíz. De esta forma, por ejemplo, para la palabra "desempleado" extendimos su carga emocional a todas las palabras que compartan la misma raíz "desemple*". Una vez asignado los sentimientos a las palabras, realizamos un análisis descriptivo de los sentimientos asociados a dichas palabra. Para ello calcularíamos el sentimiento neto como la diferencia entre el número de palabras asignadas con sentimiento positivo y el número de palabras asignadas con sentimiento negativo, es decir, $sentimiento = positivo - negativo$ [@silge_text_2017].

Para el análisis de coocurrencias, utilizamos como unidad de análisis la localidad. Así, la coocurrencia se daría si dichas palabras han sido referidas en la misma localidad. Utilizamos la misma lista de _stop words_ que, para el análisis de sentimiento, para limpiar de ruido el análisis, tratando de dejar solo las palabras con significado más relevante. Para estructurar el análisis, basamos la unidad de análisis en el llamado _bigram_. El bigram refiera que el texto se separa en palabras de dos en dos, cada par formando una unidad de análisis. Con el _bigram_ como unidad de análisis podríamos realizar un análisis descriptivo de los mismos. Aun más, procedimos a explorar la coocurrencia de varios _bigarams_ dentro de cada localidad. Por medio de este análisis pudimos trazar redes de conceptos para describir problemáticas complejas. La fuerza de la relación entre estas problemáticas complejas podría se evaluada usando el coeficiente de correlación de Phi entre los diferentes _bigrams_ [@silge_text_2017]. Para calcular el coeficiente de Phi, se aplica la siguiente formula sobre una tabla de coocurrencias entre dos localidades

$$
\phi = \frac{n_11 n_00 - n_10 n_01} {\sqrt{n_1 n_0 n_.1 n_.0}}
$$


## Reflexión metodológica

La realidad social es compleja y las certezas absolutas se convierten en falacias cuando se refieren a ella. Esto es bien sabido, tanto por positivistas y funcionalistas como por humanistas y estructuralistas. Lazarsfeld (1958) ya señalo la multidimensionalidad de la realidad social y la imposibilidad de modelar la realidad social en su plena complejidad. No obstante, bien es cierto que los positivistas/funcionalistas se han enfrentado al conocimiento de la realidad social tratando de reducir su complejidad, identificando sus elementos más elementales a base de “navajazos” en su interminable búsqueda de teorías estables y extrapolables. Por su lado, humanistas/estructuralistas han abrazado la complejidad en su totalidad, desde perspectivas holistas en las que “todo cabe” y que necesariamente genera conocimientos muy detallados, pero necesariamente volátiles y locales.

Puesto que la complejidad y variabilidad de la realidad social es infinita resultaría cuanto menos frustrante pretender abarcarla toda. Del mismo modo, puesto que es tan compleja y cambiante, resultaría inútil quedarse solo con las premisas más estables, por ser sencillas y haber sido despojadas de todo lo variable. El entendimiento de la realidad social sería mejor abarcado cuando teorías estables con premisas elementales guían el conocimiento comprehensivo del fenómeno complejo y dinámicos, detallándolos en su máxima expresión para volver a reducirlo a sus elementos más estables; aquellos que volverán a guiar el proceso. Así, con la forma de un cable de teléfono —porque no es un proceso cíclico— se suceden la lógica inductiva y la deductiva; y entre medias la abductiva. Según donde cortemos el cable encontraremos metodologías CUAN-CUAL o CUAL-CUAN, o puramente cuantitativas o cualitativas. 

Ni que decir tiene que todo lo de arriba no es más que una vaga reflexión sobre epistemología en ciencias sociales. Sin embargo, quizás sirva para mostrar como la simplificación de lo complejo también tiene su utilidad para favorecer el entendimiento y la comunicación. En ocasiones, estas simplificaciones dejan cabos sueltos o ideas esbozadas, pero no detalladas, que sirven de desencadenantes para desarrollos más completos. Así, muy someramente, hemos mencionado la lógica abductiva. Con la lógica abductiva se hipotetiza un caso a partir de unas características y un resultado [@ferro_induccion_2012]. Esto bien se podría traducir: a partir del análisis del pasado y del presente se establece una hipótesis de futuro; o como refiere [@amoros_inteligencia_2006] los estudios de prospectiva, por medio del análisis estratégico, recogen y analizan información características y resultados del pasado y del presente para realizar conjeturas, para generar casos de futuro.

Sobre esta base epistemológica, la prospectiva recogería tanto información desarrollada desde una perspectiva estructuralista como aquella desarrollada desde una perspectiva funcionalista, es decir todo tipo de información relevante sobre el pasado y el presente para, por medio de un enfoque estructuralista y una lógica abductiva, proponer posibilidades —que no probabilidades— de futuros alternativos. Así entendida, una predicción como resultado en el presente y desarrollada desde un enfoque funcionalista, puede servir de base para una conjetura sobre futuro formulada desde un enfoque estructuralista. La predicción no es el objetivo, la conclusión de la prospectiva, pero si es una información para tener en cuenta, en cuanto relevante. 

Así, se convertiría la prospectiva en una metodología con base epistemológica en la lógica abductiva y planteada desde un enfoque estructuralista. Por medio de información exhaustiva y variada del pasado y del presente, la procesa desde un entendimiento multidimensional y cambiante de la realidad social y con un enfoque holístico. Pretendería con todo ofrecer hipótesis comprehensivas sobre futuros posibles con el propósito y objetivo último de promover la acción (pro-acción) en el presente para influir en el futuro. La predicción, como “símil” funcionalista de la prospectiva, pretende reducir la complejidad y la variabilidad de la realidad social, para encontrar los elementos estables que permitan generar el escenario futuro más probable. Tanto un enfoque como el otro se complementarían en el entendimiento de la realidad social cuando nos referimos al futuro. Si bien ya hemos referido arriba como la predicción es abarcada por la prospectiva; también la predicción puede hacer uso de la prospectiva para con su “navaja” reducir los planteamientos prospectivos e incorporarlos a un modelo predictivo.

Ahora bien, la predicción y el enfoque funcionalista en el que se basa tiene como estrategia de aproximación a la realidad social su reducción, la reducción de la complejidad y el cambio, de la incertidumbre, para poder modelarla y ofrecer resultados probables y estables. La predicción nos lleva así a lo que @amoros_inteligencia_2006 refiere como una actitud preactiva en la que la acción es reducida a la adaptación a un futuro que se considera inalterable —más probable. Se reduce la posibilidad de creatividad y, más aún, se reduce el conocimiento necesario para la creatividad en la acción. En resumen, la complejidad no se gestiona, se reduce. Que es sino la media aritmética más que la reducción de la varianza de dos resultados a una única conclusión más estable. Si mantenemos la variabilidad, necesariamente mantendremos dos resultados. Es aquí donde la prospectiva con su enfoque estructuralista emerge como complemento. Desde una aproximación holística a la multidimensionalidad y dinamismo de la realidad social, la prospectiva no reduce la incertidumbre, si no que la gestiona para producir múltiples alternativas derivadas de un conocimiento comprehensivo y extenso que permita una aproximación a la acción que @amoros_inteligencia_2006 define como proactiva, en la cual es futuro es incierto —no por casualidad se plantean múltiples alternativas— y es la acción en el presente la que terminará definiéndolo.

Mientras que la predicción encontraba sus raíces en la lógica deductiva y el reduccionismo como aproximación a la realidad social; la prospectiva se servía de la lógica inductiva —y más concretamente la abductiva— para plantear una aproximación holística. Planteadas entonces desde filosofías diferentes ambas generan conocimientos complementarios. Detrás de cada acción racional —no instintiva— se encuentra un conocimiento, sea este lego o científico; también los hay erróneos. Si la epistemología define nuestra aproximación al conocimiento, por extensión también lo hace para la acción. Así desde conocimientos adquiridos por la predicción y su aproximación funcionalista se generan conocimientos reducidos pero estables —plantean un único escenario, el más probable— que condiciona una actitud preactiva hacia el cambio. Las acciones derivadas de dicha actitud están encaminadas a adaptarse a ese escenario [@amoros_inteligencia_2006]; aunque también puede generarse acciones para evitar o modificar ese escenario. Si entendemos que cualquier acción en el presente cambia el futuro, esto no es menos cierto para predicciones planteadas desde aproximaciones funcionalistas y acciones realizadas en base a ellas. En cualquier caso, toda acción quedará reducida al escenario planteado. No consideramos que la predicción genere un conocimiento determinista y absoluto que escape al control por acción. Si consideramos que lo que genera es un conocimiento reducido y parcial que derivara en acciones reducidas y parciales sobre la realidad. Una aproximación así resulta conveniente para acciones a corto plazo, focalizadas sobre un escenario probable; ahora, también los resultados tenderán a ser a corto plazo and parciales. Sin embargo, estas predicciones no proveen del conocimiento necesario para la toma de decisiones estratégica. El conocimiento reducido que ofrecen lo impide, y puesto que no van más allá del escenario más probable planteado están lejos de contribuir al conocimiento de las consecuencias de la acción. 

Es aquí donde la prospectiva y su aproximación estructuralista permiten ir más allá del corto plazo y del escenario probable. Desde el entendimiento holístico y complejo de la realidad —no reducido— esta es aprehendida con toda su diversidad y, necesariamente, ofrecerá escenarios diversos de futuro. Mas aun, será capaz de superar la barrera “del punto A al punto B” que ofrece la predicción para adentrarse en caminos hacia el futuro y desarrollar redes complejas de causalidad que desembocan en escenarios diferente. Esta aproximación permite la toma de decesiones estratégicas enfocadas al medio y largo plazo, y ofrecen un conocimiento que permitirá entender las consecuencias de la acción y, por tanto, la capacidad de definir cómo queremos cambiar.

Trasladando el uso de los estudios de futuro a la Acción Humanitaria, nos encontramos que ésta es, por definición, a corto plazo y temporal. Está destinada a contextos de crisis, de cambio constante, y a desaparecer cuando la crisis desaparece. Así los estudios de futuro rara vez han interesado al sector tradicional que, sobre bases asistencialistas, se ha limitado a cubrir necesidades básicas tratando de no entrar en cuestiones que no conciernen al actor humanitario —sino al estado nacional donde se desarrolla. Sin embargo, en la última década se viene produciendo un cambio de percepción en la Acción Humanitaria con el concepto de _Nexus_: el vínculo entre la Acción Humanitaria y el Desarrollo. Lo que siempre se había planteado como un binomio —dos formas de acción para escenarios diferente— hoy en día se entiende desde una perspectiva de la lógica borrosa (Kosko, 2000, citado por Bas, 2011) como una escala de grises en la que se enmarcan acciones que encaminan a una sociedad en crisis a una situación estable, homeostática, en la cual se ha resurgido con mayor capacidad y resiliencia frente a futuros eventos de crisis.

Este nexo entre acción humanitaria y desarrollo despierta entonces el interés por el futuro. La acción humanitaria supera las concepciones asistencialistas y el corto plazo al vincularse al desarrollo, aunque las ideas de la prospectiva están lejos aún de ser adoptadas en el sector. Cogiendo como referente los tipos de aproximación al futuro y la línea temporal que traza Bas (2012, citado en Bas, 2014), la acción humanitaria todavía se encuentra en el paso del tipo técnico al emancipatorio. 

Así, en los últimos cinco años se ha apreciado un interés por la predicción y el uso de la inteligencia artificial que permita generar modelos para mejorar la planificación y promover cambio al corto plazo. Semejantes predicciones permiten, por ejemplo, plantear el escenario más probable de desplazamientos de población y sus características. Se permite así una mejor planificación de la logística de la ayuda humanitaria, así como anticipar proyectos tanto en origen como en destino para cambiar los patrones, inicialmente predichos, de desplazamiento. Este tipo de estudio de futuro y los conocimientos reducidos que proveen son útiles en acción humanitaria por cuanto aún queda de corto plazo cuando las necesidades que se manifiestan son de supervivencia. Sin embargo, son claramente insuficientes cuando se plantean en el marco del Nexus, ya que no permiten visibilizar más allá de la crisis presente y encaminar la acción hacia un escenario de desarrollo. Las técnicas predictivas de tipo técnico solo permiten ver lo que ocurrirá, si nada cambia (Bas, 2011). Están carentes de visión estratégica y generan acciones reactivas al contexto con limitada capacidad transformadora.

Ahora bien, también se ha visto en los últimos años un creciente número de programas que incorporan conceptos como el empoderamiento, la participación y la transversalidad, conceptos en esencia prestados desde el Desarrollo y que necesariamente superan la lógica reduccionista en su identificación, pues para ser abarcados implican una aproximación holística y compleja, una aproximación estructuralista. Estos conceptos y las idea que transmiten son claves para la acción humanitaria entendida desde el Nexus. La acción humanitaria se genera por agentes externos a la sociedad la cual además se encuentra vulnerada en su situación de crisis que afecta a todas las dimensiones de la vida y con una extrema pérdida de capacidad. Entonces el empoderamiento, la participación y la transversalidad son cuestiones éticas y de estricta necesidad para evitar caer en una forma de poscolonialismo con la acción humanitaria como herramienta. Que actores externos planten estrategias de desarrollo a largo plazo sobre sociedad en crisis, sin promover la participación, el empoderamiento y la transversalidad en sus acciones solo puede conducir a un poscolonialismo y al fracaso sistemático de la acción humanitaria. Solo conducirá a una _protacted crisis_.

Si desde la acción humanitaria se van a plantear acciones con el objetivo de producir un cambio social que lleve a la sociedad a una situación estable y propicia para el desarrollo, serán necesarias cinco condiciones para la acción humanitaria (Bas ,2014): 1) Pragmatismo: que cubra necesidades manifiestas para la sociedad; 2) Contextualización: que este fundamentada en el conocimiento del contexto; 3) Sostenibilidad: que supere el espectro coyuntural que suponen los marcos políticos derivados de las agencias donantes; 4) Visión global: abierto a la capitalización y el aprendizaje de experiencias internacionales, siempre para ser adaptas al contexto; 5) Visión estratégica: superación del asistencialismo y la visión cortoplacista para integrar objetivos transformadores a medio y largo plazo. A estas condiciones se sumarian principios éticos de: 1) Empoderamiento: incrementar las capacidades y la autonomía de la sociedad en crisis; 2) Participación: involucrarla tanto en la generación de conocimiento como la acción derivada del mismo; 3) Transversalidad: superar la acción en silos –el sistema de clústeres– para incorporar la complejidad de la realidad y aprehender las consecuencias de la acción.

Es con estas condiciones y con estos principios que la Acción Humanitaria en el marco del Nexus se acerca a una cultura de innovación que mantiene el centro en las personas y en la sociedad en crisis -_people centred approach_; que está abierta a un conocimiento holístico de la realidad contextualizada; que es capaz superar el corto plazo y mirar más allá de la acción inmediata; por tanto es capaz de plantear múltiples escenarios a largo plazo y evaluarlos; y no menos es capaz de desarrollar acciones para encaminar a la sociedad hacia el escenario deseado. Todo ello con la participación y el empoderamiento de la sociedad en crisis como ejes centrales de la acción. Con todo, es capaz de innovar en su acción para el cambio social. Es capaz de comprehender la evolución de una situación de crisis a una situación de desarrollo, y mantener una práctica ética.
Si bien hemos reflexionada sobre la predicción y la prospectiva, será difícil en este trabajo aproximarse a ese nivel de análisis. Lo que pretendemos aquí, no obstante, es un paso previo basado en un nivel de análisis inferior, en el cual encontraríamos el símil de la descripción y la explicación. Sin, métodos cuantitativos/funcionalistas nos acercan a una descripción detallada de la realidad, mientras que los métodos cualitativos/estructuralista ofrecen una explicación del porqué de esa realidad. 

## Limitaciones

Además de estas consideraciones en el plano epistemológico, merece la pena resalta aquí algunas limitaciones practicas sobre el análisis que pretendimos. El contexto palestino es un contexto muy sensible, donde la información recogida de los beneficiarios de ayuda humanitaria se considera confidencial, especialmente la información cualitativa sin procesar. Esta información rara vez está abierta al público, e incluso dentro del sector humanitario, rara vez se comparte entre organizaciones. Esto nos limitó para poder acceder a información cualitativa con mayor cobertura geográfica que permitiera extender nuestro análisis cualitativo a otras áreas de Cisjordania, y a otras tipologías. 

Las particularidades del contexto en palestina impidieron la aplicación de un teselado de Voronoi que pudieran haber vinculado ambas bases de datos a al nivel de la localidad. Mientras en otros contextos esto pudiera ser posible, habría siempre que mirar a la distribución geográfica de las tipologías para aplicar esta técnica para vincular ambas bases de datos.

La sensibilidad del contexto también provoco que la información cualitativa no proviniera de grabaciones o transcripciones, si no de notas de cuadernos de campo. Si bien, en la acción humanitaria es rara vez posible realizar grabaciones, bien por recursos para analizarlas sistemáticamente mediante codificación, o simplemente para transcribirlas, o bien por sensibilidad del contexto y de los temas tratados. Esto implica necesariamente una pérdida de detalle y profundidad en la información cualitativa.

Las bases de datos utilizadas provienen de fuentes secundarias independientes. Por un lado, esto es una ventaja ya que permite utilizar información existente de fuentes comunes en la acción humanitaria, tales como son las evaluaciones multisectoriales y los grupos de discusión con beneficiarios de acción humanitaria. En cualquier caso, también implica que las unidades son independientes y no necesariamente se pueden vincular a nivel de la unidad de análisis. Esta implicación la agregación de información para una vinculación a nivel de base de datos, u, otra alternativa, su vinculación por medio de la triangulación de resultados. Esto limita la capacidad de realizar análisis más complejos a nivel de la unidad que permitan articular la información cuantitativa y cualitativa.

